{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # for working with arraya\n",
    "import matplotlib.pyplot as plt  # for drawing beautiful charts\n",
    "import pandas as pd  # for preprocess and importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n",
      "-----------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "-----------------------------------------------\n",
      "             Age        Salary\n",
      "count   9.000000      9.000000\n",
      "mean   38.777778  63777.777778\n",
      "std     7.693793  12265.579662\n",
      "min    27.000000  48000.000000\n",
      "25%    35.000000  54000.000000\n",
      "50%    38.000000  61000.000000\n",
      "75%    44.000000  72000.000000\n",
      "max    50.000000  83000.000000\n",
      "-----------------------------------------------\n",
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "-----------------------------------------------\n",
      "   Country   Age   Salary Purchased\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n",
      "-----------------------------------------------\n",
      "[['France' 44.0 72000.0 'No']\n",
      " ['Spain' 27.0 48000.0 'Yes']\n",
      " ['Germany' 30.0 54000.0 'No']\n",
      " ['Spain' 38.0 61000.0 'No']\n",
      " ['Germany' 40.0 nan 'Yes']\n",
      " ['France' 35.0 58000.0 'Yes']\n",
      " ['Spain' nan 52000.0 'No']\n",
      " ['France' 48.0 79000.0 'Yes']\n",
      " ['Germany' 50.0 83000.0 'No']\n",
      " ['France' 37.0 67000.0 'Yes']]\n",
      "-----------------------------------------------\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "print(dataset)\n",
    "print('-----------------------------------------------')\n",
    "print(type(dataset))\n",
    "print('-----------------------------------------------')\n",
    "print(dataset.describe())\n",
    "print('-----------------------------------------------')\n",
    "print(dataset.head(3))\n",
    "print('-----------------------------------------------')\n",
    "print(dataset.tail())\n",
    "print('-----------------------------------------------')\n",
    "print(dataset.values)\n",
    "print('-----------------------------------------------')\n",
    "print(type(dataset.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 3)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.values\n",
    "x = dataset[:, :-1]\n",
    "y = dataset[:, -1]\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(type(x))\n",
    "print(type(y))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taking care of missing data\n",
    " - if no. of missing entries are very less compared to data size we have ==> we can delete them/drop them\n",
    " - Otherwise, we can either replace missing values with average values.\n",
    " - In case of categorical values, we can replace missing values with maximum occurred categorical value\n",
    " - We can also replace missing categorical values in the same proportion as other categorical values present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x after imputer fit:\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "-----------------------------------------------\n",
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 nan]\n",
      " [35.0 58000.0]\n",
      " [nan 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n",
      "-----------------------------------------------\n",
      "[[4.40000000e+01 7.20000000e+04]\n",
      " [2.70000000e+01 4.80000000e+04]\n",
      " [3.00000000e+01 5.40000000e+04]\n",
      " [3.80000000e+01 6.10000000e+04]\n",
      " [4.00000000e+01 6.37777778e+04]\n",
      " [3.50000000e+01 5.80000000e+04]\n",
      " [3.87777778e+01 5.20000000e+04]\n",
      " [4.80000000e+01 7.90000000e+04]\n",
      " [5.00000000e+01 8.30000000e+04]\n",
      " [3.70000000e+01 6.70000000e+04]]\n",
      "-----------------------------------------------\n",
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 nan]\n",
      " [35.0 58000.0]\n",
      " [nan 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n",
      "-----------------------------------------------\n",
      "x after imputer transform:\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x[:,1:3])\n",
    "print(\"x after imputer fit:\")\n",
    "print(x)\n",
    "print('-----------------------------------------------')\n",
    "print(x[:,1:3])\n",
    "print('-----------------------------------------------')\n",
    "print(imputer.transform(x[:,1:3]))\n",
    "print('-----------------------------------------------')\n",
    "print(x[:,1:3])\n",
    "print('-----------------------------------------------')\n",
    "x[:,1:3]=imputer.transform(x[:,1:3]) # it returns the array with averaging out missing values, and doesn't modify in the array itself\n",
    "print(\"x after imputer transform:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the independent variable\n",
    "  - string values which we can't compare; where one value is neither less nor greater than another.\n",
    "  - Like: name of person, city he lives in, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [0.0 1.0 0.0 0.0 35.0 58000.0]\n",
      " [1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 0.0 48.0 79000.0]\n",
      " [1.0 0.0 1.0 0.0 50.0 83000.0]\n",
      " [0.0 1.0 0.0 0.0 37.0 67000.0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = ct.fit_transform(x)\n",
    "print(x)\n",
    "print(type(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the dependent variable\n",
    "  - string values which can be compared.\n",
    "  - Like: Did person bought: yes or no; grade in exams: a,b,c,d,e,f; etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n",
      "<class 'numpy.ndarray'>\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set\n",
    " - We must split our dataset first, and then go for feature scaling.\n",
    " - This is because, the data that will be given to us for prediction, will not be known to us beforehand. So, even for testing data, we want to maintain the ideal state. If we do feature scaling on whole dataset, it will be like leakage of future data. As we have already taken in account the data, that we were supposed to be unaware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [0.0 1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 0.0 48.0 79000.0]\n",
      " [1.0 0.0 1.0 0.0 50.0 83000.0]\n",
      " [0.0 1.0 0.0 0.0 35.0 58000.0]]\n",
      "[[1.0 0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 1.0 0.0 0.0 37.0 67000.0]]\n",
      "[0 1 0 0 1 1 0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature scaling\n",
    " - is done, so that higher value columns don't ignore lower value columns\n",
    " - values after feature scaling generally ranges between (-3 to 3).\n",
    " - we should not apply feature scaling on the categorical data that we encode. Because, that way, they will lose their meaning. France column value '1', means person was from France. After feature scaling, if value becomes 0.3, what will it mean.\n",
    " - For training data, we use 'fit_transform'.\n",
    " - For testing data, we must use 'transform', as we wish to transform them on the scale of testing data. As, test data will not be known before hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 1.2909944487358056 -0.19159184384578545 -1.0781259408412425]\n",
      " [1.0 0.0 1.0 -0.7745966692414834 -0.014117293757057777\n",
      "  -0.07013167641635372]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 0.566708506533324 0.633562432710455]\n",
      " [1.0 0.0 0.0 1.2909944487358056 -0.30453019390224867\n",
      "  -0.30786617274297867]\n",
      " [1.0 0.0 0.0 1.2909944487358056 -1.9018011447007988 -1.420463615551582]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 1.1475343068237058 1.232653363453549]\n",
      " [1.0 0.0 1.0 -0.7745966692414834 1.4379472069688968 1.5749910381638885]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 -0.7401495441200351 -0.5646194287757332]]\n",
      "[[1.0 0.0 1.0 -0.7745966692414834 -1.4661817944830124 -0.9069571034860727]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 -0.44973664397484414 0.2056403393225306]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
    "x_test[:, 3:] = sc.transform(x_test[:, 3:])\n",
    "print(x_train)\n",
    "print(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
